{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Behavioral Data Analysis - Change Detection Task\n",
    "\n",
    "Notes: Using manual git uploads for now. Consider installing widget\n",
    "Integer Division 'requires' python 3. Cowan's K otherwise null. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 |Anaconda 4.2.0 (32-bit)| (default, Jun 29 2016, 11:42:13) [MSC v.1500 32 bit (Intel)]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Emulate py3\n",
    "from __future__ import (absolute_import, division,\n",
    "                            print_function, unicode_literals)\n",
    "from builtins import *\n",
    "# Integer division may result in null if not run with Python > 3\n",
    "   \n",
    "import sys\n",
    "print(sys.version)\n",
    "#if sys.version[0][0] < 3:\n",
    "    #del #future stuff....\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Current directory is D:\\analysis\\pomo\\notebook\\alpha\\behavior\\data\\\n"
     ]
    }
   ],
   "source": [
    "''' Prepare Data for Import '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' Analysis of Behavioral Data\n",
    "\n",
    "Example input file (Line breaks represent CSV)\n",
    "\n",
    "0\t ,\n",
    "1\t23,\n",
    "2\tf,\n",
    "3\tSubliminal CDT July 2016,\n",
    "4\t0,\n",
    "5\tlo,\n",
    "6\t3,\n",
    "7\tnon-match,\n",
    "8\tleft,\n",
    "9\t999999,\n",
    "10\tFA,\n",
    "11\t592,\n",
    "12\t\"(['BLACK', 'RED', 'BLUE'],\n",
    "\t\t['BLACK', 'BLACK', 'GREEN'])\",\n",
    "13\t\"([-4.833454718581354, -2.8824553987581445, -2.3081588355080522],\n",
    "\t\t[-0.0037853209621609984, -2.8078914856435437, -0.31239484357072067],\n",
    "\t\t[3.86559432251519, 4.653214540852498, 1.83731757692552],\n",
    "\t\t[-1.3117916221511483, 1.866184035822822, -3.2871611286588642])\",\n",
    "14\t\"(['BLACK', 'RED', 'GREEN'],\n",
    "\t\t['BLACK', 'BLACK', 'GREEN'])\"\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import inspect\n",
    "from os import getcwd, path, walk\n",
    "\n",
    "print(60 * '=')\n",
    "#\n",
    "#\n",
    "# Experiment Configuration #\n",
    "#\n",
    "#\n",
    "\n",
    "items = [2, 3, 4, 5]\n",
    "\n",
    "current_dir = getcwd() + path.sep + 'data' + path.sep\n",
    "\n",
    "print('Current directory is ' + current_dir)\n",
    "\n",
    "# Stackoverflow Recipe\n",
    "f = []\n",
    "for (dirpath, dirname, filename) in walk(current_dir):\n",
    "    f.extend(filename)\n",
    "    break\n",
    "    \n",
    "#files = pd.Series(f)\n",
    "#print(files)\n",
    "\n",
    "\n",
    "#from itertools import iter\n",
    "# Initialize Data Accumulation\n",
    "iter_files = iter(f) #np.nditer(f)\n",
    "current_iteration = 0 # Subject ID\n",
    "\n",
    "#name = 'ewabre_py_2016-05-16 13-41-12.756000.log'\n",
    "# TODO WARNING Notice the error of the header for coordinates and colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-602-94850ebe15fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcurrent_iteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current file is {}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_iteration += 1\n",
    "filename = iter_files.next()\n",
    "print('Current file is {}...'.format(filename))\n",
    "\n",
    "filename = path.join(current_dir, filename)\n",
    "\n",
    "file_data = np.genfromtxt(\n",
    "\tfilename,\n",
    "\tdtype = None,\n",
    "\tnames = True,\n",
    "\tdelimiter = ',',\n",
    "\tmissing_values = (999999),\n",
    "\tusecols = (1,2,4,5,6,7,8,9,10) # TODO Ignoring stimulus data for now\n",
    ")\n",
    "\n",
    "d = file_data.ndim\n",
    "file_data = np.reshape(file_data,(file_data.size, 1))\n",
    "\n",
    "print('Dim reshaped from {} to {}'.format(d, file_data.ndim))\n",
    "\n",
    "#print('File Preview: ')\n",
    "# Print the first 4 rows\n",
    "#print(file_data[0:4])\n",
    "\n",
    "print(60 * '-')\n",
    "# Remove illegal responses\n",
    "l = len(file_data)\n",
    "file_data = file_data[file_data['RT'] < 7000]\n",
    "#print(file_data)\n",
    "print('Missing Values Removed: {}'.format(l - len(file_data)))\n",
    "#print(file_data[0:4])\n",
    "print(60 * '^')\n",
    "\n",
    "# Compute Signal Detection Theory (SDT) measures\n",
    "print('Level: Subject')\n",
    "r = file_data['Response']\n",
    "print('{} responses'.format(len(r)))\n",
    "hit = len(r[r == b'HIT'])\n",
    "miss = len(r[r == b'MISS'])\n",
    "fa = len(r[r == b'FA'])\n",
    "cr = len(r[r == b'CR'])\n",
    "total = hit + miss + fa + cr\n",
    "assert len(r) == total\n",
    "\n",
    "print('Total Valid Trials {}'.format(total))\n",
    "hitrate = 100 * hit / total\n",
    "farate = 100 * fa / total\n",
    "print('Hits: {}\\nMisses: {}\\nFalse Alarms: {}\\nCorrect Responses: {}'.format(hit,miss,fa,cr))\n",
    "\n",
    "# Rounding\n",
    "decimals = 2\n",
    "\n",
    "print('Hit{2}: {0}%\\nFalse Alarm{2}: {1}%\\n[of valid responses]'.format(round(hitrate, decimals),round(farate, decimals),'rate'))\n",
    "\n",
    "print('Level: Per Item in Subject')\n",
    "print('Items: {}'.format(items))\n",
    "\n",
    "#  Compute Cowan's K for all items\n",
    " \n",
    "file_data = pd.DataFrame(file_data)\n",
    "\n",
    "#print(file_data)\n",
    "\n",
    "data = file_data\n",
    "\n",
    "'''a'''\n",
    "\n",
    "'''TODO Groupby Subject ID... Accumulate'''\n",
    "agg_responses_per_items = data.groupby(['Items', 'Response']).aggregate(pd.DataFrame.count)['Response']\n",
    "agg_responses_per_items\n",
    "\n",
    "from sys import modules, version\n",
    "# Guardian clause for integer division\n",
    "# ON ERROR: Run the initial notebook imports again, located at the top of the file.\n",
    "assert ('__future__' in sys.modules) or (sys.version[0][0] > 2)\n",
    "\n",
    "# For each item get total and individual SDT values\n",
    "\n",
    "a = agg_responses_per_items # Shorthand\n",
    "\n",
    "#agg_responses_per_items.loc[:,['CR']]\n",
    "#ai = np.nditer(a, flags=['multi_index'])\n",
    "# no clue what setting this flag or not does. preserves multi_index? #ainoflag = np.nditer(a)\n",
    "\n",
    "# Helper function\n",
    "fun = lambda x: np.asarray(x)\n",
    "\n",
    "#\n",
    "# Signal Detection Measures\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "totali = fun([sum(a.loc[i,:]) for i in items])\n",
    "hi = fun(a.loc[:, ['HIT']])\n",
    "fai = fun(a.loc[:, ['FA']])\n",
    "cri = fun(a.loc[:, ['CR']])\n",
    "mi = fun(a.loc[:, ['MISS']])\n",
    "\n",
    "# Rounding precision\n",
    "decimals = 2 \n",
    "\n",
    "# False Alarm Rate (False Positive Rate)\n",
    "# NTS: Might be iteresting to look at the ratios here... assuming the limit corresponds to a quanta - i.e. a limited resource (limes being the quantum) - that can be partially distributed....\n",
    "print('FAs: {}'.format(np.round(fai / totali * 100, decimals)))\n",
    "\n",
    "\n",
    "# The original\n",
    "# (H + CR - 1) * N\n",
    "\n",
    "# Vector of items\n",
    "N = fun(items)\n",
    "\n",
    "# Because we had fun, we can by means of symbolical math compute Cowan's K thus\n",
    "ck1 = np.round( ( (hi + cri - 1) / totali ), decimals)\n",
    "ck2 = np.round( ( N * (hi - fai) / totali ), decimals)\n",
    "k_zero = np.round( (ck1 + ck2) / 2 , decimals)\n",
    "global_total = sum(a)\n",
    "\n",
    "\n",
    "# Stratified samples of n trials weighted by evidence per item\n",
    "# Compute the item percentage of the total sample\n",
    "strata_weights = totali / global_total\n",
    "# Compute the mean percentage\n",
    "mean_weight = np.mean(strata_weights)\n",
    "# Center the weights around the mean percentage by subtracting the mean\n",
    "mean_centered_weights = strata_weights - mean_weight\n",
    "\n",
    "print(strata_weights)\n",
    "print(mean_centered_weights)\n",
    "ck_error = 1 - (ck1 + ck2) / 2\n",
    "\n",
    "new_weights = mean_centered_weights + 1\n",
    "print(new_weights)\n",
    "\n",
    "\n",
    "# Just checking if using numpy results in 32-bit mess or if 64bit precision is kept.\n",
    "# Great. Test passed.\n",
    "#print('{}{}'.format(type(new_weights[0]), type(strata_ck1[0])))\n",
    "\n",
    "# Finally, weigh Cowan's k+ and k-\n",
    "strata_ck1 = np.round(new_weights * ck1, decimals)\n",
    "strata_ck2 = np.round(new_weights * ck2, decimals)\n",
    "\n",
    "# For each item\n",
    "ones = fun(len(items) * [1])\n",
    "\n",
    "#lk_error = (ck2 - ck1) / 2\n",
    "\n",
    "# Print debug information\n",
    "print('Per Item (2, 3, 4, 5)')\n",
    "print('Total: {}\\nHits: {}\\nFalse Alarms: {}'.format(totali, hi, fai))\n",
    "print('Cowan''s k+: {}'.format(ck1))\n",
    "print('Cowan''s k-: {}'.format(ck2))\n",
    "print('Cowan''s k0: {}'.format(k_zero))\n",
    "print(60 * '#')\n",
    "print('{}{}{}{}{}{}'.format(ck1, ck2, k_zero, ck_error, strata_ck1, strata_ck2))\n",
    "print(60 * '#')\n",
    "print('k error: {}'.format(ck_error))\n",
    "print('k+ weighted by coefficents (stratified sampling): {}'.format(strata_ck1))\n",
    "print('k- weighted by coefficents (stratified sampling): {}'.format(strata_ck2))\n",
    "\n",
    "if current_iteration == 1:\n",
    "    big_data = pd.DataFrame(data=[ck1, ck2, k_zero, ck_error, strata_ck1, strata_ck2])\n",
    "else:\n",
    "    next_data = pd.DataFrame(data=[ck1, ck2, k_zero, ck_error, strata_ck1, strata_ck2])\n",
    "\n",
    "try:\n",
    "    big_data = pd.DataFrame.append(big_data, next_data)\n",
    "except StopIteration:\n",
    "    print('Reached STOPITERATION')\n",
    "finally:\n",
    "    pass\n",
    "\n",
    "big_data.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-618-fe983d35336d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbig_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'big_data.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbig_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mxw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Anaconda2\\lib\\site-packages\\pandas\\io\\excel.pyc\u001b[0m in \u001b[0;36mwrite_cells\u001b[0;34m(self, cells, sheet_name, startrow, startcol)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_conv_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m             \u001b[0mnum_format_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'val'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2      3     4     5     0     1     2      3  ...      2  \\\n",
       "0  0.92  0.82  0.87  0.130  0.91  0.81  0.97  0.91  0.94  0.060  ...   0.81   \n",
       "1  0.80  0.87  0.84  0.165  0.82  0.89  0.94  1.38  1.16 -0.160  ...   0.84   \n",
       "2  0.84  1.39  1.12 -0.115  0.84  1.38  0.85  1.48  1.16 -0.165  ...   1.06   \n",
       "3  0.75  1.57  1.16 -0.160  0.74  1.55  0.84  1.79  1.32 -0.315  ...   1.23   \n",
       "\n",
       "       3     4     5     0     1     2      3     4     5  \n",
       "0  0.190  0.96  0.76  0.90  0.71  0.80  0.195  0.89  0.70  \n",
       "1  0.160  0.62  0.71  0.81  1.03  0.92  0.080  0.83  1.05  \n",
       "2 -0.065  0.90  1.39  0.70  1.01  0.86  0.145  0.69  1.00  \n",
       "3 -0.230  0.83  1.79  0.66  0.67  0.66  0.335  0.66  0.67  \n",
       "\n",
       "[4 rows x 90 columns]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xw = pd.io.api.ExcelWriter('data1.xlsx')\n",
    "big_data.T.to_excel(xw,'Sheet1')\n",
    "xw.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cowan's *k*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cowan's\n",
    "\\begin{equation*}\n",
    "k_{-} = N * (h + c - 1)\n",
    "\\end{equation*}\n",
    "\n",
    "Cowan's\n",
    "\\begin{equation*}\n",
    "k_{+} = N * (h - f)\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-CR, 3-CR, 4-CR, 5-CR, 2-FA, 3-FA, 4-FA, 5-FA, 2-HIT, 3-HIT, 4-HIT, 5-HIT, 2-MISS, 3-MISS, 4-MISS, 5-MISS\n"
     ]
    }
   ],
   "source": [
    "# Generate Labels\n",
    "\n",
    "ITEMS_ = 0\n",
    "SDT_ = 1\n",
    "\n",
    "a = agg_responses_per_items\n",
    "step_item = len(a.index.levels[ITEMS_])\n",
    "len_agg = len(a.index.labels[ITEMS_])\n",
    "\n",
    "#start = 0\n",
    "#stop = len_agg\n",
    "\n",
    "#item_mask = [i for i in range(start, stop, step_item)]\n",
    "#print(item_mask)\n",
    "\n",
    "#sdt_mask = a.index.labels[SDT_]\n",
    "## DEBUGGABLE TODO --- MAY not return for other items than a quadruple, e.g. [2,3,4,5]\n",
    "#[i for i in step_item * range(start, step_item)] #replace step_item\n",
    "#print(sdt_mask)\n",
    "\n",
    "multi_label = ''\n",
    "\n",
    "sep = ', '\n",
    "for i in a.index.levels[SDT_]:\n",
    "    for j in a.index.levels[ITEMS_]:\n",
    "        multi_label += '{}-{}{}'.format(j, i, sep)\n",
    "\n",
    "# Trim last separator\n",
    "multi_label = multi_label[0:-len(sep)]\n",
    "\n",
    "print(multi_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TODO: Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Response Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Items  Response\n",
       "2      CR          449.0\n",
       "       FA          428.0\n",
       "       HIT         388.5\n",
       "       MISS        429.5\n",
       "3      CR          470.5\n",
       "       FA          457.0\n",
       "       HIT         415.0\n",
       "       MISS        472.0\n",
       "4      CR          480.0\n",
       "       FA          421.0\n",
       "       HIT         436.0\n",
       "       MISS        469.0\n",
       "5      CR          477.0\n",
       "       FA          494.0\n",
       "       HIT         441.5\n",
       "       MISS        466.0\n",
       "Name: RT, dtype: float64"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_median_rt_per_items = data.groupby(['Items', 'Response']).aggregate(pd.DataFrame.median)['RT']\n",
    "agg_median_rt_per_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Items  Response\n",
       "2      CR           58.162974\n",
       "       FA           95.333333\n",
       "       HIT          56.668269\n",
       "       MISS         80.968750\n",
       "3      CR           59.967705\n",
       "       FA           56.231009\n",
       "       HIT          56.982022\n",
       "       MISS         58.312925\n",
       "4      CR           51.043159\n",
       "       FA           61.152355\n",
       "       HIT          76.826978\n",
       "       MISS         57.515571\n",
       "5      CR           63.691106\n",
       "       FA          126.451524\n",
       "       HIT          85.273554\n",
       "       MISS         56.144044\n",
       "Name: RT, dtype: float64"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_mad_rt_per_items = data.groupby(['Items', 'Response']).aggregate(pd.DataFrame.mad)['RT']\n",
    "agg_mad_rt_per_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "</br></br></br></br></br>\n",
    "*The End (for now...)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
